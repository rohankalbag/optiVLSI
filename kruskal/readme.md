# Kruskal's Algorithm


## How is this useful in VLSI 

- This is a very powerful algorithm especially in dense VLSI circuits, especially in those with having components with lots of [fan-outs and fan-ins](https://en.wikipedia.org/wiki/Fan-out).
- The minimum spanning tree generates a configuration of all the components present with connections reducing the total wire length.
-  MSTs can be used to optimize the distribution of power in a VLSI circuit. By creating an MST of the power distribution network, the most efficient path for power delivery can be determined, reducing the overall power consumption of the circuit
- They can also be used to place components in an optimized layout such that signal integrity is improved, especially with signals such as **CLK** which are needed in almost all components for synchronization of the circuit.
- For MST creation, VLSI circuits are modelled as undirected graphs as this is used to study the topology/layout of the circuit, as MSTs are only defined for undirected graphs, unlike in the case of shortest path algorithm, where circuits are modelled as directed acyclic graphs
- Kruskal's algorithm makes use of a sorted edge list and a disjoint-set-union data structure


## How to setup Python environment

- make virtual environment for python : `python3 -m venv kruskal`
- activate virtual environment: `source kruskal/bin/activate`
- set up libraries required for kruskal's algorithm: `pip install -r requirements.txt`

- we are making use of automan to compare the performance of the following
- 1. numba njit accelerated kruskal's algorithm (`kruskal_numba_accelerated`)
- 2. regular pythonic kruskal's algorithm (`kruskal_pythonic`)
- 3. networkx implementation of kruskal's algorithm (`kruskal_networkx`), uses [(`nx.minimum_spanning_tree(algorithm = 'kruskal')`)](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.tree.mst.minimum_spanning_tree.html)


## Usage of `kruskal.py`

```bash
python3 kruskal_algorithm.py --b (optional) [--c -n size -p prob -w1 minw1 -w2 minw2 ]/[--f] -m fileloc -t treeloc   
```
- if `--c` flag is passed this script directly creates a benchmark of size n and probability p using the `gnp_random_graph()` which generates erdos renyi graphs which are DAGs (Directed Acyclic Graph), then a undirected version of it is created and made use of

- $n$ here denotes the number of nodes in the graph

- $p$ here denotes the probability of a particular pair of nodes $i, j$ to have an edge between them, and is independent of $i$ and $j$.
- the graph is stored as numpy arrays of nodes and edgelist in `fileloc.npz` 

- if `--f` flag is passed then we need to specify the graph we are feeding to it by passing it filename as `-m fileloc` if our benchmark maze is stored in `fileloc.npz` 

- if `--b` flag is used then benchmarking will be done using `time.perf_counter()` and the time taken by each of the methods will be printed on three lines in the order (numba, python, networkx)

- Irrespective of the flags, the script will produce two `.pdf` files each containing the graph generated by the script/passed to the script (in `fileloc.pdf`) and one with shortest path highlighted (in `treeloc.pdf`) and also print the shortest path obtained all three methods one by one, both the graphs are also stored in `.npz` format as well


## Some Examples

`python3 kruskal.py --c -n 6 -w1 2 -w2 5 -p 0.5 -m graph -t mst --b`

### Outputs Obtained

```
0.0001223610001943598
0.0004708410001512675
2.0770999981323257e-05
```

#### `graph.pdf`


#### `mst.pdf`



## Benchmarking using Automan
- to run the automan scripts which benchmarks for given values of maze size run `python3 automate.py`
- the plot generated by automan can be found in `/manuscripts/figures/Kruskal`

### Results Obtained on Benchmarking
> Values of maze size chosen were $n \in \{10, 20, 50, 100, 150, 200, 350, 400, 500\}$ 


- the speedup wrt to the numba accelerated version seems to increase with the size of the graph and the numba accelerated is nearly 100 times faster than the networkx implementation, this may be due to the overhead of creating the graph, the numba accelerated version is nearly 50 times faster than regular pythonic implementation
